{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Car brand classification.ipynb",
      "provenance": [],
      "mount_file_id": "16h_JOLMmyKF48zUNWXShhxFtvVKzoFTc",
      "authorship_tag": "ABX9TyMOciuj7Gt8pTZ2jb+AkM4u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pouyaaskari/Car-Brand-classification-with-Resnet50/blob/master/Car_brand_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VFy7GXH9Vy3"
      },
      "source": [
        "# #0-Dataset have 3 labels and is available in my google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7E_f9UNhXimh",
        "outputId": "822f005b-8fa2-4fea-d5d9-f01c32fdd76e"
      },
      "source": [
        "!unzip /content/Deep-Learning-Car-Brand/Datasets.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/Deep-Learning-Car-Brand/Datasets.zip\n",
            "   creating: Datasets/Test/\n",
            "   creating: Datasets/Test/audi/\n",
            "  inflating: Datasets/Test/audi/21.jpg  \n",
            "  inflating: Datasets/Test/audi/22.jpg  \n",
            "  inflating: Datasets/Test/audi/23.jpg  \n",
            "  inflating: Datasets/Test/audi/24.jpg  \n",
            "  inflating: Datasets/Test/audi/25.jpg  \n",
            "  inflating: Datasets/Test/audi/26.jpg  \n",
            "  inflating: Datasets/Test/audi/27.jpg  \n",
            " extracting: Datasets/Test/audi/28.jpg  \n",
            "  inflating: Datasets/Test/audi/29.jpg  \n",
            "   creating: Datasets/Test/lamborghini/\n",
            "  inflating: Datasets/Test/lamborghini/1.jpg  \n",
            "  inflating: Datasets/Test/lamborghini/10.jpg  \n",
            "  inflating: Datasets/Test/lamborghini/11.jpg  \n",
            "  inflating: Datasets/Test/lamborghini/12.jpg  \n",
            "  inflating: Datasets/Test/lamborghini/13.jpg  \n",
            "  inflating: Datasets/Test/lamborghini/14.jpg  \n",
            "  inflating: Datasets/Test/lamborghini/15.jpg  \n",
            "  inflating: Datasets/Test/lamborghini/16.jpg  \n",
            "  inflating: Datasets/Test/lamborghini/17.jpg  \n",
            "  inflating: Datasets/Test/lamborghini/18.jpg  \n",
            "  inflating: Datasets/Test/lamborghini/19.jpg  \n",
            "  inflating: Datasets/Test/lamborghini/2.jpg  \n",
            "  inflating: Datasets/Test/lamborghini/20.jog.jpg  \n",
            "  inflating: Datasets/Test/lamborghini/21.jpg  \n",
            "  inflating: Datasets/Test/lamborghini/22.jpg  \n",
            "  inflating: Datasets/Test/lamborghini/23.jpg  \n",
            "  inflating: Datasets/Test/lamborghini/24.jpg  \n",
            "  inflating: Datasets/Test/lamborghini/25.jpg  \n",
            "  inflating: Datasets/Test/lamborghini/26.jpg  \n",
            "  inflating: Datasets/Test/lamborghini/27.jpg  \n",
            "  inflating: Datasets/Test/lamborghini/28.jpg  \n",
            "  inflating: Datasets/Test/lamborghini/29.jpg  \n",
            "  inflating: Datasets/Test/lamborghini/3.jpg  \n",
            "  inflating: Datasets/Test/lamborghini/30.jpg  \n",
            "  inflating: Datasets/Test/lamborghini/4.jpg  \n",
            "  inflating: Datasets/Test/lamborghini/5.jpg  \n",
            "  inflating: Datasets/Test/lamborghini/6.jpg  \n",
            "  inflating: Datasets/Test/lamborghini/7.jpg  \n",
            "  inflating: Datasets/Test/lamborghini/8.jpg  \n",
            "  inflating: Datasets/Test/lamborghini/9.jpg  \n",
            "   creating: Datasets/Test/mercedes/\n",
            "  inflating: Datasets/Test/mercedes/27.jpg  \n",
            "  inflating: Datasets/Test/mercedes/28.jpg  \n",
            "  inflating: Datasets/Test/mercedes/29.jpg  \n",
            "  inflating: Datasets/Test/mercedes/30.jpg  \n",
            "  inflating: Datasets/Test/mercedes/31.jpg  \n",
            "  inflating: Datasets/Test/mercedes/32.jpg  \n",
            "  inflating: Datasets/Test/mercedes/33.jpg  \n",
            "  inflating: Datasets/Test/mercedes/34.jpg  \n",
            "  inflating: Datasets/Test/mercedes/35.jpg  \n",
            "  inflating: Datasets/Test/mercedes/36.jpg  \n",
            "  inflating: Datasets/Test/mercedes/37.jpg  \n",
            "  inflating: Datasets/Test/mercedes/38.jpg  \n",
            "  inflating: Datasets/Test/mercedes/39.jpg  \n",
            "  inflating: Datasets/Test/mercedes/40.jpg  \n",
            "  inflating: Datasets/Test/mercedes/41.jpg  \n",
            "  inflating: Datasets/Test/mercedes/42.jpg  \n",
            "  inflating: Datasets/Test/mercedes/43.jpg  \n",
            "  inflating: Datasets/Test/mercedes/44.jpg  \n",
            "  inflating: Datasets/Test/mercedes/45.jpg  \n",
            "   creating: Datasets/Train/\n",
            "   creating: Datasets/Train/audi/\n",
            "  inflating: Datasets/Train/audi/1.jpg  \n",
            "  inflating: Datasets/Train/audi/10.jpg  \n",
            "  inflating: Datasets/Train/audi/11.jpg  \n",
            "  inflating: Datasets/Train/audi/12.jpg  \n",
            "  inflating: Datasets/Train/audi/13.jpg  \n",
            "  inflating: Datasets/Train/audi/14.jpg  \n",
            "  inflating: Datasets/Train/audi/15.jpg  \n",
            "  inflating: Datasets/Train/audi/16.jpg  \n",
            "  inflating: Datasets/Train/audi/17.jpg  \n",
            "  inflating: Datasets/Train/audi/18.jpg  \n",
            "  inflating: Datasets/Train/audi/19.jpg  \n",
            "  inflating: Datasets/Train/audi/2.jpg  \n",
            "  inflating: Datasets/Train/audi/20.jpg  \n",
            "  inflating: Datasets/Train/audi/3.jpg  \n",
            "  inflating: Datasets/Train/audi/4.jpg  \n",
            "  inflating: Datasets/Train/audi/5.jpg  \n",
            "  inflating: Datasets/Train/audi/6.jpg  \n",
            "  inflating: Datasets/Train/audi/7.jpg  \n",
            "  inflating: Datasets/Train/audi/8.jpg  \n",
            "  inflating: Datasets/Train/audi/9.jpg  \n",
            "   creating: Datasets/Train/lamborghini/\n",
            "  inflating: Datasets/Train/lamborghini/1.jpg  \n",
            "  inflating: Datasets/Train/lamborghini/10.jpg  \n",
            "  inflating: Datasets/Train/lamborghini/11.jpg  \n",
            "  inflating: Datasets/Train/lamborghini/12.jpg  \n",
            "  inflating: Datasets/Train/lamborghini/13.jpg  \n",
            "  inflating: Datasets/Train/lamborghini/14.jpg  \n",
            "  inflating: Datasets/Train/lamborghini/15.jpg  \n",
            "  inflating: Datasets/Train/lamborghini/16.jpg  \n",
            "  inflating: Datasets/Train/lamborghini/17.jpg  \n",
            "  inflating: Datasets/Train/lamborghini/18.jpg  \n",
            "  inflating: Datasets/Train/lamborghini/19.jpg  \n",
            "  inflating: Datasets/Train/lamborghini/2.jpg  \n",
            "  inflating: Datasets/Train/lamborghini/3.jpg  \n",
            "  inflating: Datasets/Train/lamborghini/4.jpg  \n",
            "  inflating: Datasets/Train/lamborghini/5.jpg  \n",
            "  inflating: Datasets/Train/lamborghini/6.jpg  \n",
            "  inflating: Datasets/Train/lamborghini/7.jpg  \n",
            "  inflating: Datasets/Train/lamborghini/8.jpg  \n",
            "  inflating: Datasets/Train/lamborghini/9.jpg  \n",
            "   creating: Datasets/Train/mercedes/\n",
            "  inflating: Datasets/Train/mercedes/1.jpg  \n",
            "  inflating: Datasets/Train/mercedes/10.jpg  \n",
            "  inflating: Datasets/Train/mercedes/11.jpg  \n",
            "  inflating: Datasets/Train/mercedes/12.jpg  \n",
            "  inflating: Datasets/Train/mercedes/13.jpg  \n",
            "  inflating: Datasets/Train/mercedes/14.jpg  \n",
            "  inflating: Datasets/Train/mercedes/15.jpg  \n",
            "  inflating: Datasets/Train/mercedes/16.jpg  \n",
            "  inflating: Datasets/Train/mercedes/17.jpg  \n",
            "  inflating: Datasets/Train/mercedes/18.jpg  \n",
            "  inflating: Datasets/Train/mercedes/19.jpg  \n",
            "  inflating: Datasets/Train/mercedes/2.jpg  \n",
            "  inflating: Datasets/Train/mercedes/20.jpg  \n",
            "  inflating: Datasets/Train/mercedes/21.jpg  \n",
            "  inflating: Datasets/Train/mercedes/22.jpg  \n",
            "  inflating: Datasets/Train/mercedes/23.jpg  \n",
            "  inflating: Datasets/Train/mercedes/24.jpg  \n",
            "  inflating: Datasets/Train/mercedes/25.jpg  \n",
            " extracting: Datasets/Train/mercedes/3.jpg  \n",
            " extracting: Datasets/Train/mercedes/4.jpg  \n",
            "  inflating: Datasets/Train/mercedes/5.jpg  \n",
            "  inflating: Datasets/Train/mercedes/6.jpg  \n",
            "  inflating: Datasets/Train/mercedes/7.jpg  \n",
            "  inflating: Datasets/Train/mercedes/8.jpf.jpg  \n",
            "  inflating: Datasets/Train/mercedes/9.jpg  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBuFedKoYOI2"
      },
      "source": [
        "#1-Import necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7bKuVW-YUFt"
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras.layers import Input,Lambda,Dense,Flatten,Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50,preprocess_input\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator,load_img\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGdysyobdvje"
      },
      "source": [
        "#2-load data and resnet weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SaQFpH5dxvB"
      },
      "source": [
        "image_size=[224,224]\n",
        "folder=glob(\"/content/drive/MyDrive/Colab Notebooks/Datasets/Train/*\")\n",
        "\n",
        "train=\"/content/drive/MyDrive/Colab Notebooks/Datasets/Train\"\n",
        "test=\"/content/drive/MyDrive/Colab Notebooks/Datasets/Test\"\n",
        "\n",
        "resnet=ResNet50(input_shape=image_size+[3],weights=\"imagenet\",include_top=False)\n",
        "\n",
        "for layer in resnet.layers:\n",
        "  layer.trainable=False"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSrf8GDcjrC0"
      },
      "source": [
        "#3-make our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64jIkMZFjuUP"
      },
      "source": [
        "x=Flatten()(resnet.output)\n",
        "x=Dense(10,activation=\"relu\")(x)\n",
        "output=Dense(len(folder),activation=\"softmax\")(x)\n",
        "\n",
        "#create our model\n",
        "model=Model(inputs=resnet.input,outputs=output)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHLvVihloyvZ",
        "outputId": "002069e8-506a-446e-a6f8-16405d56fd5d"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_7 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
            "                                                                 conv2_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
            "                                                                 conv2_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
            "                                                                 conv3_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
            "                                                                 conv3_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
            "                                                                 conv4_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
            "                                                                 conv4_block6_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
            "                                                                 conv5_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "flatten_6 (Flatten)             (None, 100352)       0           conv5_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense_17 (Dense)                (None, 10)           1003530     flatten_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_18 (Dense)                (None, 3)            33          dense_17[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 24,591,275\n",
            "Trainable params: 1,003,563\n",
            "Non-trainable params: 23,587,712\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0Q9x4z_pjFR"
      },
      "source": [
        "#4-compile our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbEKXZ0PppF7"
      },
      "source": [
        "model.compile(loss=\"categorical_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOjt2hNsp9d3"
      },
      "source": [
        "#5-Let's make more data with Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXbFNbNHqHVj"
      },
      "source": [
        "train_datagen=ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "test_datagen=ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LyId_OFlq08Z",
        "outputId": "51863057-2e0f-48a4-af36-6a9a4f3e533b"
      },
      "source": [
        "train_set=train_datagen.flow_from_directory(\"/content/drive/MyDrive/Colab Notebooks/Datasets/Train\",\n",
        "                                            target_size=(224,224),\n",
        "                                            batch_size=32,\n",
        "                                            class_mode=\"categorical\")"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 64 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ql9RDQN6s8h7",
        "outputId": "0c4e393a-c820-4579-956c-32dbbcd768ae"
      },
      "source": [
        "test_set=test_datagen.flow_from_directory(\"/content/drive/MyDrive/Colab Notebooks/Datasets/Test\",\n",
        "                                          target_size=(224,224),\n",
        "                                          batch_size=32,class_mode=\"categorical\")"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 58 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PRxQ47wtPkJ",
        "outputId": "bdf0cfd3-6a6a-413e-9fbe-ff6da0884d79"
      },
      "source": [
        "history=model.fit(\n",
        "    train_set,validation_data=test_set,epochs=100,steps_per_epoch=len(train_set),validation_steps=len(test_set)\n",
        ")"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "2/2 [==============================] - 7s 2s/step - loss: 1.9814 - accuracy: 0.3438 - val_loss: 1.1505 - val_accuracy: 0.3276\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 1.0123 - accuracy: 0.4375 - val_loss: 1.0978 - val_accuracy: 0.5172\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 1.0988 - accuracy: 0.2969 - val_loss: 1.0977 - val_accuracy: 0.5172\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 1.0988 - accuracy: 0.2969 - val_loss: 1.0976 - val_accuracy: 0.5172\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 1.0988 - accuracy: 0.2969 - val_loss: 1.0975 - val_accuracy: 0.5172\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 1.0988 - accuracy: 0.2969 - val_loss: 1.0975 - val_accuracy: 0.5172\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 1.0988 - accuracy: 0.2969 - val_loss: 1.0975 - val_accuracy: 0.5172\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 1.0988 - accuracy: 0.2969 - val_loss: 1.0975 - val_accuracy: 0.5172\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 1.0987 - accuracy: 0.2969 - val_loss: 1.0976 - val_accuracy: 0.5172\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 2s 997ms/step - loss: 1.0987 - accuracy: 0.2969 - val_loss: 1.0976 - val_accuracy: 0.5172\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 1.0987 - accuracy: 0.2969 - val_loss: 1.0976 - val_accuracy: 0.5172\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 1.0985 - accuracy: 0.2969 - val_loss: 1.0977 - val_accuracy: 0.3276\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 2s 997ms/step - loss: 1.0985 - accuracy: 0.3906 - val_loss: 1.0978 - val_accuracy: 0.3276\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 1.0984 - accuracy: 0.3906 - val_loss: 1.0979 - val_accuracy: 0.3276\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 2s 991ms/step - loss: 1.0983 - accuracy: 0.3906 - val_loss: 1.0980 - val_accuracy: 0.3276\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 1.0982 - accuracy: 0.3906 - val_loss: 1.0981 - val_accuracy: 0.3276\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 2s 996ms/step - loss: 1.0982 - accuracy: 0.3906 - val_loss: 1.0982 - val_accuracy: 0.3276\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 1.0981 - accuracy: 0.3906 - val_loss: 1.0983 - val_accuracy: 0.3276\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 1.0980 - accuracy: 0.3906 - val_loss: 1.0983 - val_accuracy: 0.3276\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 1.0979 - accuracy: 0.3906 - val_loss: 1.0984 - val_accuracy: 0.3276\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 2s 998ms/step - loss: 1.0979 - accuracy: 0.3906 - val_loss: 1.0986 - val_accuracy: 0.3276\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 1.0977 - accuracy: 0.3906 - val_loss: 1.0986 - val_accuracy: 0.3276\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 1.0976 - accuracy: 0.3906 - val_loss: 1.0987 - val_accuracy: 0.3276\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 1.0976 - accuracy: 0.3906 - val_loss: 1.0988 - val_accuracy: 0.3276\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 1.0975 - accuracy: 0.3906 - val_loss: 1.0989 - val_accuracy: 0.3276\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 1.0974 - accuracy: 0.3906 - val_loss: 1.0990 - val_accuracy: 0.3276\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 1.0973 - accuracy: 0.3906 - val_loss: 1.0991 - val_accuracy: 0.3276\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 1.0972 - accuracy: 0.3906 - val_loss: 1.0993 - val_accuracy: 0.3276\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 1.0971 - accuracy: 0.3906 - val_loss: 1.0994 - val_accuracy: 0.3276\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 1.0970 - accuracy: 0.3906 - val_loss: 1.0995 - val_accuracy: 0.3276\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 1.0969 - accuracy: 0.3906 - val_loss: 1.0995 - val_accuracy: 0.3276\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 1.0968 - accuracy: 0.3906 - val_loss: 1.0996 - val_accuracy: 0.3276\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 1.0967 - accuracy: 0.3906 - val_loss: 1.0997 - val_accuracy: 0.3276\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 1.0967 - accuracy: 0.3906 - val_loss: 1.0999 - val_accuracy: 0.3276\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 1.0966 - accuracy: 0.3906 - val_loss: 1.1000 - val_accuracy: 0.3276\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 1.0965 - accuracy: 0.3906 - val_loss: 1.1001 - val_accuracy: 0.3276\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 1.0964 - accuracy: 0.3906 - val_loss: 1.1002 - val_accuracy: 0.3276\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 1.0964 - accuracy: 0.3906 - val_loss: 1.1003 - val_accuracy: 0.3276\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 1.0963 - accuracy: 0.3906 - val_loss: 1.1004 - val_accuracy: 0.3276\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 2s 993ms/step - loss: 1.0962 - accuracy: 0.3906 - val_loss: 1.1005 - val_accuracy: 0.3276\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 1.0961 - accuracy: 0.3906 - val_loss: 1.1006 - val_accuracy: 0.3276\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 1.0960 - accuracy: 0.3906 - val_loss: 1.1007 - val_accuracy: 0.3276\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 1.0959 - accuracy: 0.3906 - val_loss: 1.1008 - val_accuracy: 0.3276\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 2s 998ms/step - loss: 1.0959 - accuracy: 0.3906 - val_loss: 1.1008 - val_accuracy: 0.3276\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 2s 991ms/step - loss: 1.0958 - accuracy: 0.3906 - val_loss: 1.1009 - val_accuracy: 0.3276\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 1.0957 - accuracy: 0.3906 - val_loss: 1.1010 - val_accuracy: 0.3276\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 2s 995ms/step - loss: 1.0956 - accuracy: 0.3906 - val_loss: 1.1012 - val_accuracy: 0.3276\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 2s 993ms/step - loss: 1.0956 - accuracy: 0.3906 - val_loss: 1.1013 - val_accuracy: 0.3276\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 2s 993ms/step - loss: 1.0955 - accuracy: 0.3906 - val_loss: 1.1014 - val_accuracy: 0.3276\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 2s 994ms/step - loss: 1.0954 - accuracy: 0.3906 - val_loss: 1.1015 - val_accuracy: 0.3276\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 2s 987ms/step - loss: 1.0953 - accuracy: 0.3906 - val_loss: 1.1016 - val_accuracy: 0.3276\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 2s 997ms/step - loss: 1.0952 - accuracy: 0.3906 - val_loss: 1.1017 - val_accuracy: 0.3276\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 1.0952 - accuracy: 0.3906 - val_loss: 1.1018 - val_accuracy: 0.3276\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 2s 998ms/step - loss: 1.0952 - accuracy: 0.3906 - val_loss: 1.1019 - val_accuracy: 0.3276\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 1.0951 - accuracy: 0.3906 - val_loss: 1.1020 - val_accuracy: 0.3276\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 1.0950 - accuracy: 0.3906 - val_loss: 1.1020 - val_accuracy: 0.3276\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 1.0949 - accuracy: 0.3906 - val_loss: 1.1021 - val_accuracy: 0.3276\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 2s 992ms/step - loss: 1.0949 - accuracy: 0.3906 - val_loss: 1.1022 - val_accuracy: 0.3276\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 1.0948 - accuracy: 0.3906 - val_loss: 1.1023 - val_accuracy: 0.3276\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 1.0948 - accuracy: 0.3906 - val_loss: 1.1024 - val_accuracy: 0.3276\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 1.0947 - accuracy: 0.3906 - val_loss: 1.1025 - val_accuracy: 0.3276\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 1.0946 - accuracy: 0.3906 - val_loss: 1.1026 - val_accuracy: 0.3276\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 1.0946 - accuracy: 0.3906 - val_loss: 1.1026 - val_accuracy: 0.3276\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 1.0945 - accuracy: 0.3906 - val_loss: 1.1027 - val_accuracy: 0.3276\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 1.0945 - accuracy: 0.3906 - val_loss: 1.1028 - val_accuracy: 0.3276\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 1.0944 - accuracy: 0.3906 - val_loss: 1.1029 - val_accuracy: 0.3276\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 1.0943 - accuracy: 0.3906 - val_loss: 1.1030 - val_accuracy: 0.3276\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 1.0943 - accuracy: 0.3906 - val_loss: 1.1031 - val_accuracy: 0.3276\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 1.0943 - accuracy: 0.3906 - val_loss: 1.1031 - val_accuracy: 0.3276\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 2s 979ms/step - loss: 1.0942 - accuracy: 0.3906 - val_loss: 1.1032 - val_accuracy: 0.3276\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 1.0942 - accuracy: 0.3906 - val_loss: 1.1033 - val_accuracy: 0.3276\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 1.0941 - accuracy: 0.3906 - val_loss: 1.1034 - val_accuracy: 0.3276\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 2s 1000ms/step - loss: 1.0940 - accuracy: 0.3906 - val_loss: 1.1035 - val_accuracy: 0.3276\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 1.0940 - accuracy: 0.3906 - val_loss: 1.1036 - val_accuracy: 0.3276\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 1.0939 - accuracy: 0.3906 - val_loss: 1.1037 - val_accuracy: 0.3276\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 1.0939 - accuracy: 0.3906 - val_loss: 1.1038 - val_accuracy: 0.3276\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 1.0938 - accuracy: 0.3906 - val_loss: 1.1039 - val_accuracy: 0.3276\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 1.0938 - accuracy: 0.3906 - val_loss: 1.1040 - val_accuracy: 0.3276\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 1.0937 - accuracy: 0.3906 - val_loss: 1.1041 - val_accuracy: 0.3276\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 2s 996ms/step - loss: 1.0937 - accuracy: 0.3906 - val_loss: 1.1042 - val_accuracy: 0.3276\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 1.0937 - accuracy: 0.3906 - val_loss: 1.1043 - val_accuracy: 0.3276\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 1.0936 - accuracy: 0.3906 - val_loss: 1.1044 - val_accuracy: 0.3276\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 1.0935 - accuracy: 0.3906 - val_loss: 1.1045 - val_accuracy: 0.3276\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 1.0935 - accuracy: 0.3906 - val_loss: 1.1046 - val_accuracy: 0.3276\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 1.0935 - accuracy: 0.3906 - val_loss: 1.1048 - val_accuracy: 0.3276\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 1.0934 - accuracy: 0.3906 - val_loss: 1.1048 - val_accuracy: 0.3276\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 2s 995ms/step - loss: 1.0934 - accuracy: 0.3906 - val_loss: 1.1049 - val_accuracy: 0.3276\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 2s 984ms/step - loss: 1.0934 - accuracy: 0.3906 - val_loss: 1.1051 - val_accuracy: 0.3276\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 2s 992ms/step - loss: 1.0933 - accuracy: 0.3906 - val_loss: 1.1052 - val_accuracy: 0.3276\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 1.0933 - accuracy: 0.3906 - val_loss: 1.1052 - val_accuracy: 0.3276\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 1.0932 - accuracy: 0.3906 - val_loss: 1.1053 - val_accuracy: 0.3276\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 1.0932 - accuracy: 0.3906 - val_loss: 1.1054 - val_accuracy: 0.3276\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 1.0932 - accuracy: 0.3906 - val_loss: 1.1055 - val_accuracy: 0.3276\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 1.0931 - accuracy: 0.3906 - val_loss: 1.1055 - val_accuracy: 0.3276\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 1.0931 - accuracy: 0.3906 - val_loss: 1.1056 - val_accuracy: 0.3276\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 1.0931 - accuracy: 0.3906 - val_loss: 1.1057 - val_accuracy: 0.3276\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 1.0930 - accuracy: 0.3906 - val_loss: 1.1058 - val_accuracy: 0.3276\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 1.0930 - accuracy: 0.3906 - val_loss: 1.1059 - val_accuracy: 0.3276\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 1.0930 - accuracy: 0.3906 - val_loss: 1.1060 - val_accuracy: 0.3276\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 1.0929 - accuracy: 0.3906 - val_loss: 1.1061 - val_accuracy: 0.3276\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "x2dYxWA3ztvk",
        "outputId": "3754cf8b-655d-400c-a053-4559727423bb"
      },
      "source": [
        "plt.plot(history.history[\"loss\"],label=\"train_loss\")\n",
        "plt.plot(history.history[\"val_loss\"],label=\"test_loss\")\n",
        "plt.legend()\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.show()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idAYUFbd3G7L"
      },
      "source": [
        "#our dataset is so small and we have a high loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgHgbwTb56Hf"
      },
      "source": [
        "#6-Save the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9mxQdfJg6Adh",
        "outputId": "cd57fd65-e0c1-4ae3-e240-e9b60d40dd37"
      },
      "source": [
        "model.save(\"model.h5\")"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTSjrz4S6PuC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXQHTGFu6ToN"
      },
      "source": [
        "#7-Let's do some prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMAVt3H56Y-j",
        "outputId": "919c5ec9-ce9c-421e-ecbe-3d063e247296"
      },
      "source": [
        "pred=model.predict(test_set)\n",
        "print(pred)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.32261157 0.31426492 0.36312354]\n",
            " [0.32261157 0.31426492 0.36312354]\n",
            " [0.32261157 0.31426492 0.36312354]\n",
            " [0.32261157 0.31426492 0.36312354]\n",
            " [0.32261157 0.31426492 0.36312354]\n",
            " [0.32261157 0.31426492 0.36312354]\n",
            " [0.32261157 0.31426492 0.36312354]\n",
            " [0.32261157 0.31426492 0.36312354]\n",
            " [0.32261157 0.31426492 0.36312354]\n",
            " [0.32261157 0.31426492 0.36312354]\n",
            " [0.32261157 0.31426492 0.36312354]\n",
            " [0.32261157 0.31426492 0.36312354]\n",
            " [0.32261157 0.31426492 0.36312354]\n",
            " [0.32261157 0.31426492 0.36312354]\n",
            " [0.32261157 0.31426492 0.36312354]\n",
            " [0.32261157 0.31426492 0.36312354]\n",
            " [0.32261157 0.31426492 0.36312354]\n",
            " [0.32261157 0.31426492 0.36312354]\n",
            " [0.32261157 0.31426492 0.36312354]\n",
            " [0.32261157 0.31426492 0.36312354]\n",
            " [0.32261157 0.31426492 0.36312354]\n",
            " [0.32261157 0.31426492 0.36312354]\n",
            " [0.32261157 0.31426492 0.36312354]\n",
            " [0.32261157 0.31426492 0.36312354]\n",
            " [0.32261157 0.31426492 0.36312354]\n",
            " [0.32261157 0.31426492 0.36312354]\n",
            " [0.32261157 0.31426492 0.36312354]\n",
            " [0.32261157 0.31426492 0.36312354]\n",
            " [0.32261157 0.31426492 0.36312354]\n",
            " [0.32261157 0.31426492 0.36312354]\n",
            " [0.32261157 0.31426492 0.36312354]\n",
            " [0.32261157 0.31426492 0.36312354]\n",
            " [0.32261157 0.31426492 0.36312354]\n",
            " [0.32261157 0.31426492 0.36312354]\n",
            " [0.32261157 0.31426492 0.36312354]\n",
            " [0.32261157 0.31426492 0.36312354]\n",
            " [0.32261157 0.31426492 0.36312354]\n",
            " [0.32261157 0.31426492 0.36312354]\n",
            " [0.32261157 0.31426492 0.36312354]\n",
            " [0.32261157 0.31426492 0.36312354]\n",
            " [0.32261157 0.31426492 0.36312354]\n",
            " [0.32261157 0.31426492 0.36312354]\n",
            " [0.32261157 0.31426492 0.36312354]\n",
            " [0.32261157 0.31426492 0.36312354]\n",
            " [0.32261157 0.31426492 0.36312354]\n",
            " [0.32261157 0.31426492 0.36312354]\n",
            " [0.32261157 0.31426492 0.36312354]\n",
            " [0.32261157 0.31426492 0.36312354]\n",
            " [0.32261157 0.31426492 0.36312354]\n",
            " [0.32261157 0.31426492 0.36312354]\n",
            " [0.32261157 0.31426492 0.36312354]\n",
            " [0.32261157 0.31426492 0.36312354]\n",
            " [0.32261157 0.31426492 0.36312354]\n",
            " [0.32261157 0.31426492 0.36312354]\n",
            " [0.32261157 0.31426492 0.36312354]\n",
            " [0.32261157 0.31426492 0.36312354]\n",
            " [0.32261157 0.31426492 0.36312354]\n",
            " [0.32261157 0.31426492 0.36312354]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXRlIC9v6lCb",
        "outputId": "43d49940-639e-4c3d-bac4-226654d4bede"
      },
      "source": [
        "y_pred=np.argmax(pred,axis=1)\n",
        "print(y_pred)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qm_zohaV6uQo"
      },
      "source": [
        "model=load_model(\"model.h5\")"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKL-0QXm7HVJ"
      },
      "source": [
        "image=image.load_img(\"/content/drive/MyDrive/Colab Notebooks/Datasets/Test/mercedes/28.jpg\",target_size=(224,224))"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Psf7Qb-U7Ydf"
      },
      "source": [
        "x=tf.keras.utils.img_to_array(image)"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlDb_Ldh7epg",
        "outputId": "e4f54670-04b3-40a0-cf63-651e1c6e331f"
      },
      "source": [
        "x.shape"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(224, 224, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbJyVkBP8Pjc"
      },
      "source": [
        "x=x/255"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYDHUI-L8RWX",
        "outputId": "a3ae5751-3cce-47f4-a77f-37394bc61080"
      },
      "source": [
        "x=np.expand_dims(x,axis=0)\n",
        "image=preprocess_input(x)\n",
        "image.shape"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 224, 224, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQR6N1Vx8Z4B"
      },
      "source": [
        "a=model.predict(image)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtsIDCbM8dyv"
      },
      "source": [
        "b=np.argmax(a,axis=1)"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "foxoh02x8rD1",
        "outputId": "601b0ddd-1a21-4768-b513-cb96e70486be"
      },
      "source": [
        "print(b)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFXtu4Zq8taC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}